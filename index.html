<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>What if Eye...?</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@400;500;600;700&family=Source+Serif+4:wght@300;400;500;600&display=swap" rel="stylesheet">
    <link href="https://fonts.cdnfonts.com/css/linux-biolinum" rel="stylesheet">
    <link rel="icon" href="images/eye-favicon.png" type="image/png">

    <!-- This code snippet is used to set up Google Tag Manager (GTM) on the webpage. 
         It loads the GTM script asynchronously and initializes the data layer. 
         The gtag function is then used to configure GTM with the tracking ID 'G-RZKKHXXYQM'. 
         This is needed to enable tracking and analytics on the website, allowing the site owner to collect data on user behavior and interactions. -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-RZKKHXXYQM"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-RZKKHXXYQM');
    </script>
    <!-- End of Google Tag Manager setup -->
</head>

<body>
    <header class="hero" id="top">
        <video class="hero-video" autoplay loop muted playsinline>
            <source src="videos/eye-evolution-hero.mp4" type="video/mp4" playbackRate="100">
        </video>
        <div class="hero-overlay"></div>
        <div class="hero-top">
            <div class="brand">
                <span class="brand-title" style="font-size:1.2rem; display:block;">Artificial Cambrian Intelligence</span>
                <span class="brand-subtitle" style="font-size:0.9rem;">Evolving visual intelligence in video game worlds</span>
            </div>
            <!-- <a class="hero-pill" href="https://www.science.org/doi/10.1126/sciadv.ady2888">Published in Science Advances</a> -->
        </div>
        <div class="hero-content">
            <p class="hero-kicker">Science Advances, 2025</p>
            <h1><i>What if Eye</i>...?</h1>
            <p class="hero-lede">We evolve artificial embodied agents inside video-game worlds to replay millions of years of evolution and create new forms of artificial agents.</p>
            <!-- <p class="hero-sublede">A serious research program on how visual intelligence emerges through co-evolving bodies, sensors, and behavior.</p> -->
            <div class="hero-actions">
                <a class="button primary" href="https://www.science.org/doi/10.1126/sciadv.ady2888">Main paper (Science Advances)</a>
                <a class="button ghost" href="https://mit-genai.pubpub.org/pub/bcfcb6lu/release/3">Impact Paper (MIT Press)</a>
                <a class="button ghost" href="https://github.com/cambrian-org/ACI">Code</a>
            </div>
        </div>
        <a href="#about" class="chevron" aria-label="Scroll to content">&#x25BC;</a>
    </header>

    <main>
        <div class="page-layout">
            <aside class="toc-panel toc-panel--page" aria-label="On-page contents">
                <div class="toc-header">
                    <div class="toc-eyebrow">Contents</div>
                    <button class="toc-toggle" type="button" aria-expanded="true" aria-controls="toc-list">
                        <span class="sr-only">Toggle contents</span>
                        <span class="toggle-caret" aria-hidden="true"></span>
                    </button>
                </div>
                <ol class="toc-list" id="toc-list">
                    <li><a class="toc-link" data-target="#top" href="#top">Hero</a></li>
                    <li><a class="toc-link" data-target="#about" href="#about">Overview</a></li>
                    <li>
                        <a class="toc-link" data-target="#questions" href="#questions">What-if questions</a>
                        <ol class="toc-sublist">
                            <li><a class="toc-link" data-target="#question-goals" href="#question-goals">Goals of vision</a></li>
                            <li><a class="toc-link" data-target="#question-brains" href="#question-brains">Brains stayed small</a></li>
                            <li><a class="toc-link" data-target="#question-optics" href="#question-optics">Eyes bend light</a></li>
                        </ol>
                    </li>
                    <li><a class="toc-link" data-target="#publications" href="#publications">Publications</a></li>
                    <li><a class="toc-link" data-target="#news" href="#news">Press Coverage</a></li>
                    <li><a class="toc-link" data-target="#talks" href="#talks">Talks</a></li>
                    <li><a class="toc-link" data-target="#code" href="#code">Code</a></li>
                    <li><a class="toc-link" data-target="#exhibitions" href="#exhibitions">Exhibitions</a></li>
                </ol>
            </aside>
            <div class="page-content">
                <section class="what-if-intro" id="about">
                    <div class="content intro-body">
                        <div class="text-block">
                            <p class="section-kicker">Computationally recreating vision evolution</p>
                            <h2>A What-if Eye... Universe?</h2>
                            <p class="author-line">
                                <a href="https://kushagratiwary.com">Kushagra Tiwary*</a><sup>1</sup>,
                                <a href="https://aaronyoung5.github.io/">Aaron Young*</a><sup>1</sup>,
                                <a href="https://zaidtas.github.io/">Zaid Tasneem*</a><sup>2</sup>,
                                <a href="http://tzofi.github.io/">Tzofi Klinghoffer</a><sup>1,6</sup>,
                                <a href="https://akshatdave.github.io/">Akshat Dave</a><sup>1</sup>,
                                <a href="https://mcgovern.mit.edu/profile/tomaso-poggio/">Tomaso Poggio</a><sup>3</sup>,
                                <a href="https://portal.research.lu.se/en/persons/dan-eric-nilsson">Dan-Eric Nilsson</a><sup>4</sup>,
                                <a href="https://briancheung.github.io/">Brian Cheung**</a><sup>3,6</sup>,
                                <a href="https://www.media.mit.edu/people/raskar/overview/">Ramesh Raskar**</a><sup>1</sup>
                            </p>
                            <div class="metadata">
                                <div class="metadata-item">
                                    <div class="institution">MIT Media Lab<sup>1</sup>, Rice University<sup>2</sup>, Center for Brains Minds and Machines, MIT<sup>3</sup>, Lund Vision Group, Lund University<sup>4</sup>, InfoLab, MIT CSAIL<sup>5</sup>, Charles Stark Draper Laboratory<sup>6</sup></div>
                                </div>
                            </div>
                            <p>Evolution happened once. We build a video-game universe to replay evolution. This allows us to computationally study principles behind biological intelligence and create new forms of artificial intelligence.  </p>
                        
                            <p>Agents begin with a single light-sensing cell and evolve their visual intelligence by facing real physics, embodied constraints, and survival pressures. </p>
                        
                            <p>The point is to let visual intelligence, the ability to sense (hardware), percieve, reason, and act (software) in an environment, emerge as opposed to being engineered by fixed datasets and human biases.</p>
                        </div>
                        <div class="media-panel intro-figure">
                            <a class="intro-figure-frame" href="images/what-if-universe.png" target="_blank" rel="noopener">
                                <img class="intro-figure-image" src="images/what-if-universe.png" alt="Illustration of an alternate evolution universe">
                            </a>
                            <p class="media-caption intro-figure-caption">
                                <span style="font-size: 1.6em; display: block;">
                                    What if Darwin had an what-if evolution machine?* 
                                </span>
                                <span style="font-size: 1em; display: block; margin-top:0.5em; color: #6fafef;">
                                    *Comic inspired by the <a href="https://xkcd.com/">xkcd comics</a> and <a href="https://what-if.xkcd.com/">"What-if" books</a> by Randall Munroe
                                </span>
                            </p>
                        </div>
                    </div>
                </section>


        <section class="story" id="questions">
            <div class="content">
                <div class="section-intro align-center media-tone">
                    <h2>What-if questions about vision, answered by evolving AI agents</h2>
                    <p>Each experiment is a hypothesis that we test in our What-If Machine. We pose a what-if question or counterfactual, evolve embodied agents inside video-game-like physics engines, and watch which eyes and behaviors emerge.</p>
                </div>

                <div class="story-block reverse wash-sky text-left" id="question-goals" style="--media-col: 1fr; --text-col: 0.9fr;">
                    <div class="story-text">
                        <p class="story-question story-question--compact">What if the goals of vision were different?</p>
                        <!-- <p class="story-question story-question--compact">What if vision were only used for navigation or detection?</p> -->
                        <p>
                            We initialize our agents with one light-sensing cell and a small brain and evolve their visual intelligence
                            in a world with only two tasks:
                        </p>
                        <ol>
                            <li><b>NAVIGATION</b> where the goal is to move as fast as possible to the left while avoiding obstacles (walls of the maze).</li>
                            <li><b>DETECTION</b> where the goal is to detect the food and avoid the poison.</li>
                        </ol>
                    </div>
                    <div class="story-media">
                        <div class="media-panel media-row">
                            <video autoplay loop muted playsinline>
                                <source src="videos/navigation.mp4" type="video/mp4">
                            </video>
                            <video autoplay loop muted playsinline>
                                <source src="videos/movie-S2.mp4" type="video/mp4">
                            </video>
                        </div>
                        <p class="media-caption">
                            <b>Navigation</b> agents favor distributed, wide-coverage vision.
                        </p>
                    </div>

                    <div class="story-media">
                        <div class="media-panel media-row">
                            <video autoplay loop muted playsinline>
                                <source src="videos/detection.mp4" type="video/mp4">
                            </video>
                            <video autoplay loop muted playsinline>
                                <source src="videos/movie-S2.mp4" type="video/mp4">
                            </video>
                        </div>
                        <p class="media-caption"><b>Detection</b> favors high-acuity, forward-facing camera-like eyes.</p>
                    </div>


                </div>

                <div class="story-block reverse wash-sage" id="question-brains" style="--media-col: 1fr; --text-col: 0.9fr;">
                    <div class="story-text">
                        <p class="story-question">What if brains stayed small throughout evolution?</p>
                        <p>When we systematically scale eyes and brain size at the same time, we uncover power-law scaling between neural capacity and task performance — but only when visual acuity scales too. If acuity is bottlenecked, scaling the “brain” alone stops buying better behavior.</p>
                    </div>
                    <div class="story-media">
                        <div class="media-panel ai-panel">
                            <img class="ai-scaling-figure" src="images/ai-scaling.png" alt="AI scaling laws figure">
                            <p class="media-caption">Scaling laws in AI (Kaplan et&nbsp;al., 2020) relate test loss to compute, dataset size, and parameters, without accounting for an agent’s visual acuity. In embodied settings, we show that acuity matters because it compresses the representation the agent receives from the world.</p>
                        </div>
                    </div>
                    <div class="story-text">
                        <div class="media-panel">
                            <img class="bio-scaling-figure" src="images/biological-scaling-law.png" alt="Biological scaling laws figure">
                            <p class="media-caption">In biology, we observe scaling between eyes and brains across animals. Figure from "The scaling of eye size in adult birds: Relationship to brain, head and body sizes" (Richard Burton). We show that this scaling behavior can be reproduced with our agents.</p>
                        </div>
                    </div>
                    <div class="story-media">
                        <div class="media-panel">
                            <div class="media-row brains-video">
                                <video autoplay loop muted playsinline>
                                    <source src="videos/section2p5_detection.mp4" type="video/mp4">
                                </video>
                                <img src="images/detection-scaling-2.png" alt="Detection scaling plot">
                            </div>
                            <p class="media-caption media-caption--single"><b>Scaling detection performance as eyes and brains grow together.</b> Each blue line represents agents trained with the same visual acuity but larger number of parameters. Darker blue lines represent higher visual acuity.</p>
                        </div>
                    </div>
                </div>

                <div class="story-block reverse wash-lilac" id="question-optics" style="--media-col: 1.1fr; --text-col: 0.9fr;">
                    <div class="story-text">
                        <p class="story-question">What if eyes could bend light?</p>
                        <p>When we enable optical genes, evolution repeatedly discovers lens-like optics because they solve a brutal constraint:</p>
                        <ul>
                            <li><b>Without optics</b>, systems hit a hard ceiling — pinhole strategies can sharpen images only by sacrificing light.</li>
                            <li><b>With optics</b>, lenses emerge as a solution to the fundamental tradeoff between light collection and spatial precision.</li>
                        </ul>
                        <div class="media-panel" style="display: flex; flex-direction: column; align-items: center; justify-content: flex-start; gap: 12px;">
                            <img src="images/pupil2-nobg.png" alt="Pupil experiment visualization"
                                 style="width: 100%; height: auto; max-width: 360px; border-radius: 12px; box-shadow: 0 2px 16px rgba(80,90,110,0.10);">
                            <p class="media-caption" style="max-width: 480px; margin-top: 0.2rem; text-align: center;">
                                Optics evolve from open → cup → pinhole → unfocused lens → focused lens. Lenses preserve spatial precision while allowing larger pupils for more light.
                            </p>
                        </div>
                    </div>
                    <div class="story-media">
                        <div class="media-panel" style="display: flex; flex-direction: column; align-items: flex-start; justify-content: flex-start; gap: 12px;">
                            <video autoplay loop muted playsinline style="max-width: 560px; width: 100%; height: auto; margin: 0; display: block; object-fit: contain;">
                                <source src="videos/section2p4_movie.mp4" type="video/mp4">
                            </video>
                            <p class="media-caption" style="max-width: 520px; margin-top: 0.2rem;">
                                The yellow frustrum indicates the light being collected by the eye. The pinhole eye collects less light but has higher reward than the open eye. Once the agents evolve lenses, they can collect more light and have higher acuity so they learn more robust behaviors as a result.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="resources" id="resources">
            <div class="content">
                <div class="section-intro">
                    <h2>Publications, talks, code, and exhibitions</h2>
                    <p>Explore our publications, roadmaps, talks, open-source tools, and public exhibits.</p>
                </div>

                <div class="resource-group" id="publications">
                    <h3 class="resource-subhead">Publications</h3>
                    <div class="resource-grid">
                        <article class="resource-card pastel-lilac">
                            <div class="resource-header">
                                <h4>Computationally Recreating Vision Evolution</h4>
                                <span class="tag">Science Advances</span>
                            </div>
                            <img class="resource-image" src="images/SA-paper.png" alt="Science Advances paper figure">
                            <p>The peer-reviewed publication detailing the full experimental setup, results, and evolutionary analysis.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://www.science.org/doi/10.1126/sciadv.ady2888">Paper (open access)</a>
                                <a class="mini-link" href="https://eyes.mit.edu/what-if">Blog Post</a>
                                <a class="mini-link" href="sciadv.ady2888.pdf">PDF</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-sand">
                            <div class="resource-header">
                                <h4>A Roadmap for Generative Design of Visual Intelligence</h4>
                                <span class="tag">MIT Press</span>
                            </div>
                            <img class="resource-image" src="images/Roadmap-paper.png" alt="Roadmap paper figure">
                            <p>Why should we generate and not hand design visual intelligence? We discuss why it's important, the applications of doing so, and how to get there.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://mit-genai.pubpub.org/pub/bcfcb6lu/release/3">Impact Paper</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-sage">
                            <div class="resource-header">
                                <h4>Designing Imaging Systems with Reinforcement Learning</h4>
                                <span class="tag">ICCV</span>
                            </div>
                            <img class="resource-image" src="images/diser-paper.png" alt="DISER paper figure">
                            <p>We propose a new way to codesign imaging systems and task-specific perception models based on feedback from the environment.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://tzofi.com/diser">Project Page</a>
                                <a class="mini-link" href="https://arxiv.org/abs/2309.13851">PDF</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-peach">
                            <div class="resource-header">
                                <h4>Emergence of foveal image sampling from learning to attend in visual scene</h4>
                                <span class="tag">NeurIPS</span>
                            </div>
                            <img class="resource-image" src="videos/fovea-emerge.gif" alt="Foveal image sampling from learning to attend in visual scene">
                            <p>We show that learning to attend in visual scenes leads to foveal image sampling, a key visual system feature.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://arxiv.org/abs/1611.09430">PDF</a>
                                <a class="mini-link" href="https://bair.berkeley.edu/blog/2017/11/09/learn-to-attend-fovea/">Blog Post</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-sky">
                            <div class="resource-header">
                                <h4>Designing neural network architectures using reinforcement learning</h4>
                                <span class="tag">ICLR</span>
                            </div>
                            <img class="resource-image" src="images/nas.png" alt="NAS paper figure">
                            <p>We design neural network architectures using reinforcement learning to improve performance on visual tasks.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://arxiv.org/abs/1611.02167">PDF</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-rose">
                            <div class="resource-header">
                                <h4>Upcoming work!</h4>
                                <span class="tag">Coming soon</span>
                            </div>
                            <p>We are working on a lot of exciting things that we will be releasing soon! We are always 
                                looking for collaborators and partners to work with in expanding our work to new domains. 
                                Feel free to reach out to us to join our team!.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="mailto:ktiwary@mit.edu">Email us</a>
                            </div>
                        </article>

                    </div>
                </div>

                <div class="resource-group" id="news">
                    <h3 class="resource-subhead">Press Coverage</h3>
                    <div class="resource-grid">
                        <article class="resource-card pastel-sky">
                            <div class="resource-header">
                                <span class="tag">MIT News</span>
                            </div>
                            <img class="resource-image" src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/202512/MIT_Eye-Evolution-01_0.jpg?itok=K_ijrSP2" alt="MIT News logo">
                            <p>A “scientific sandbox” lets researchers explore the evolution of vision systems</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://news.mit.edu/2025/scientific-sandbox-lets-researchers-explore-evolution-vision-systems-1217">MIT News</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-sand">
                            <div class="resource-header">
                                <span class="tag">MIT News</span>
                            </div>
                            <img class="resource-image" src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/202403/MIT-GenAI-01-press_0.jpg?itok=sYOzPylJ" alt="MIT scholars awarded generative AI seed grants">
                            <p>MIT scholars awarded a second round of seed grants for generative AI research</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://news.mit.edu/2024/mit-scholars-awarded-second-round-seed-grants-generative-ai-0328">MIT News (2024)</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-sage">
                            <div class="resource-header">
                                <span class="tag">Science News</span>
                            </div>
                            <img class="resource-image" src="images/science-news.jpeg" alt="Science News logo">
                            <p>Why have so many different eyes evolved? Gamelike simulation could provide answers</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://www.science.org/content/article/why-have-so-many-different-eyes-evolved-gamelike-simulation-could-provide-answers">Science News</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-peach">
                            <div class="resource-header">
                                <span class="tag">Hacker News</span>
                            </div>
                            <img class="resource-image" src="https://news.ycombinator.com/favicon.ico" alt="Hacker News logo">
                            <div class="mini-links">
                                <a class="mini-link" href="https://news.ycombinator.com/item?id=43043063">Y Combinator</a>
                            </div>
                        </article>
                        <article class="resource-card pastel-peach">
                            <div class="resource-header">
                                <span class="tag">Forbes News</span>
                            </div>
                            <img class="resource-image" src="https://imageio.forbes.com/specials-images/imageserve/679a5d9bb8e9823c0c29bc6f/Neuron-system/0x0.jpg?width=960&dpr=1" alt="Forbes logo">
                            <p>Beyond computer vision: brains in jars and how they see.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://www.forbes.com/sites/johnwerner/2025/07/02/beyond-computer-vision-brains-in-jars-and-how-they-see/">Forbes</a>
                            </div>
                        </article>
                        
                    </div>
                </div>

                <div class="resource-group" id="talks">
                    <h3 class="resource-subhead">Talks</h3>
                    <div class="resource-grid">
                        <article class="resource-card pastel-mint">
                            <div class="resource-header">
                                <span class="tag">UC Berkeley</span>
                            </div>
                            <img class="resource-image" src="images/redwood-recording.png" alt="Redwood Talk at UC Berkeley">
                            <p>Highlights from a talk at UC Berkeley's Redwood Center by Kushagra Tiwary. Covers the project vision and open research questions.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://redwood.berkeley.edu/seminars/kushagra-tiwary-june-2025">Talk Details</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-peach">
                            <div class="resource-header">
                                <span class="tag">Tedx Talk</span>
                            </div>
                            <img class="resource-image" src="https://img.youtube.com/vi/OuPwGkzh6nM/hqdefault.jpg" alt="Tedx Talk Thumbnail">
                            <p>Tedx talk exploring the broader implications of evolving visual intelligence with artificial agents.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://www.youtube.com/watch?v=OuPwGkzh6nM">Watch Video</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-sky">
                            <div class="resource-header">
                                <span class="tag">Coming Soon</span>
                            </div>
                            <!-- <img class="resource-image" src="images/talk-coming-soon.png" alt="Placeholder for upcoming talk" style="opacity: 0.7;"> -->
                            <p>More talks and presentations are on their way! Stay tuned for upcoming speaking events and recordings.</p>
                            <div class="mini-links">
                                <span class="mini-link">Coming soon</span>
                            </div>
                        </article>
                    </div>
                </div>

                <div class="resource-group" id="code">
                    <h3 class="resource-subhead">Code</h3>
                    <div class="resource-grid">
                        <article class="resource-card pastel-sage">
                            <div class="resource-header">
                                <h4>Simulator</h4>
                                <span class="tag">Open Source</span>
                            </div>
                            <p>Run the evolutionary simulator, define new tasks, and evolve your own embodied agents.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://github.com/cambrian-org/ACI">GitHub</a>
                                <a class="mini-link" href="https://eyes.mit.edu/ACI">Documentation</a>
                                <a class="mini-link" href="https://eyes.mit.edu/ACI/examples/index.html">Examples</a>
                            </div>
                        </article>

                        <article class="resource-card pastel-sky">
                            <div class="resource-header">
                                <h4>Colab Notebook (coming soon)</h4>
                                <span class="tag">Notebook</span>
                            </div>
                            <p>Interactive notebooks for experimenting with Cambrian agents directly in the browser.</p>
                            <div class="mini-links">
                                <span class="mini-link">Coming soon</span>
                            </div>
                        </article>
                    </div>
                </div>

                <div class="resource-group" id="exhibitions">
                    <h3 class="resource-subhead">Exhibitions</h3>
                    <div class="resource-grid resource-grid--wide">
                        <article class="resource-card pastel-peach">
                            <div class="resource-header">
                                <h4>Video Exhibition</h4>
                                <span class="tag">Public Engagement</span>
                            </div>
                            <video autoplay loop muted playsinline style="max-width: 100%; width: 100%; height: auto; margin: 0; display: block;">
                                <source src="videos/firstsignsofvision-exhibition.mp4" type="video/mp4">
                                <track kind="captions">
                                <script>
                                    // 10x speed video play
                                    document.addEventListener("DOMContentLoaded", function () {
                                        var videos = document.querySelectorAll('video');
                                        videos.forEach(function(video) {
                                            // Find the desired <source>
                                            var source = Array.from(video.getElementsByTagName('source')).find(src => src.src.includes("firstsignsofvision-exhibition"));
                                            if (source) {
                                                video.playbackRate = 10.0;
                                            }
                                        });
                                    });
                                </script>
                            </video>
                            <p>How can we interact with evolution? Our exhibitions let visitors experience evolving vision in a hands-on way.</p>
                            <div class="mini-links">
                                <a class="mini-link" href="https://eyes.mit.edu/exhibitions/mit-museum">MIT Museum After Dark</a>
                                <a class="mini-link" href="https://eyes.mit.edu/exhibitions/mos">Museum of Science Boston</a>
                            </div>
                        </article>
                    </div>
                </div>
            </div>
        </section>

        <section class="affiliations" id="affiliations">
            <div class="content">
                <div class="logo-row">
                    <div style="display: flex; gap: 32px; align-items: center; flex-wrap: wrap;">
                        <!-- <img src="images/mit-logo.png" alt="MIT" style="height:70px;"> -->
                        <img src="images/camera-culture-nobg.png" alt="MIT Media Lab, Camera Culture" style="height:100px;">
                        <img src="images/cbmm.png" alt="Center for Brains Minds and Machines, MIT" style="height:80px;">
                        <!-- <img src="images/mas.webp" alt="MIT Media Lab, Camera Culture" style="height:90px;"> -->
                        <img src="images/csail.png" alt="InfoLab, MIT CSAIL" style="height:90px;">
                        <img src="images/lund.svg" alt="Lund Vision Group" style="height:90px;">
                    </div>
                    <p>A collaboration supported by the <a href="https://news.mit.edu/2024/mit-scholars-awarded-second-round-seed-grants-generative-ai-0328">MIT GenAI Impacts of Generative AI Grant</a>.</p>
                </div>
            </div>
        </section>
            </div>
        </div>
    </main>


    <footer>
        <div class="content">
            <p>Copyright 2025 Kushagra Tiwary. All rights reserved.</p>
            <div class="links">
                <a href="mailto:ktiwary@mit.edu,aryoung@mit.edu">Contact</a>
                <a href="https://github.com/cambrian-org/ACI">GitHub</a>
                <a href="#">Twitter</a>
            </div>
            <a href="https://accessibility.mit.edu" class="accessibility">MIT Accessibility</a>
        </div>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const toc = document.querySelector('.toc-panel');
            if (!toc) return;

            const toggle = toc.querySelector('.toc-toggle');
            const tocLinks = Array.from(toc.querySelectorAll('.toc-link'));
            let autoCollapsed = false;

            const setCollapsed = (collapsed) => {
                toc.classList.toggle('is-collapsed', collapsed);
                toggle.setAttribute('aria-expanded', (!collapsed).toString());
            };

            // Ensure the contents panel starts open on initial load
            setCollapsed(false);

            toggle.addEventListener('click', () => {
                const collapsed = toc.classList.toggle('is-collapsed');
                autoCollapsed = false;
                toggle.setAttribute('aria-expanded', (!collapsed).toString());
            });

            // No auto-collapse on scroll; stays open unless user toggles it

            const pairs = tocLinks
                .map(link => {
                    const target = document.querySelector(link.dataset.target);
                    return target ? { link, target } : null;
                })
                .filter(Boolean);

            const activateLink = (id) => {
                tocLinks.forEach(link => {
                    const isActive = link.dataset.target === `#${id}`;
                    link.classList.toggle('is-active', isActive);
                    if (isActive) {
                        link.setAttribute('aria-current', 'location');
                    } else {
                        link.removeAttribute('aria-current');
                    }
                });
            };

            const observer = new IntersectionObserver((entries) => {
                const visible = entries
                    .filter(entry => entry.isIntersecting)
                    .sort((a, b) => b.intersectionRatio - a.intersectionRatio);

                if (visible.length > 0) {
                    activateLink(visible[0].target.id);
                } else {
                    // Fallback: find the last section above the viewport midpoint
                    const viewportMid = window.scrollY + window.innerHeight * 0.4;
                    const best = pairs
                        .map(({ target }) => ({ id: target.id, top: target.getBoundingClientRect().top + window.scrollY }))
                        .filter(s => s.top <= viewportMid)
                        .sort((a, b) => b.top - a.top)[0];
                    if (best) activateLink(best.id);
                }
            }, {
                rootMargin: '-25% 0px -55% 0px',
                threshold: [0.1, 0.3, 0.5, 0.7, 0.9]
            });

            pairs.forEach(({ target }) => observer.observe(target));

            // Rely on pure CSS `position: sticky` for the Contents panel
        });
    </script>
</body>

</html>
